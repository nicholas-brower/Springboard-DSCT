{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frankfurt Stock Exchange: Carl Zeiss Meditec in 2017**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing modules and defining constants.\n",
    "<br><i>NASDAQ_DATE_FMT added after inspecting sample data.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "from itertools import filterfalse\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.request import urlopen, Request\n",
    "from statistics import fmean, median\n",
    "from collections import namedtuple, Counter\n",
    "from textwrap import fill\n",
    "\n",
    "from nasdaq_cred import api_key\n",
    "\n",
    "API_KEY = api_key\n",
    "NASDAQ_DATE_FMT = '%Y-%m-%d'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions\n",
    "<br><br><i>TLDR:</i><br>\n",
    "<b>nasdaq_json_dict</b> gets a JSON object from NASDAQ API and returns a dictionary. \n",
    "<br><b>dict_agg</b> returns the result of aggregate calculations performed on a dictionary grouped by a column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasdaq_json_dict(\n",
    "        market: str, stock_sym: str, **params) -> dict:\n",
    "    '''Request a JSON object from NASDAQ API. Return it as a dictionary\n",
    "    \n",
    "    Arguments:\n",
    "    market -- stock market abbreviation\n",
    "    stock_sym -- stock symbol\n",
    "    **params -- parameters. see below\n",
    "    https://docs.data.nasdaq.com/docs/in-depth-usage\n",
    "    \n",
    "    Return a decoded JSON object as a dictionary\n",
    "    '''\n",
    "    q_url = f'https://data.nasdaq.com/api/v3/datasets/'\n",
    "    q_url = q_url + f'{market}/{stock_sym}.json?'\n",
    "    if params:\n",
    "        q_url = q_url + '&'.join(\n",
    "            f'{key}={val}' for key, val in params.items()\n",
    "        )\n",
    "    q_url = f'{q_url}&api_key={API_KEY}'\n",
    "    with urlopen(Request(q_url)) as response:\n",
    "         return json.load(response)\n",
    "        \n",
    "def hr(character: str = '_' ) -> str:\n",
    "    '''Return a string of 79 * char for use as a text divider. Default\n",
    "    character value is underscore to mimic html horizontal rule <hr>\n",
    "    '''\n",
    "    return 79 * character\n",
    "\n",
    "def print_vars(**variables) -> None:\n",
    "    '''Print linespaced variable name and variable separated by divider.\n",
    "    Print the variable's type and length if applicable\n",
    "    '''\n",
    "    for var_name, var in variables.items():\n",
    "        print(f'{var_name}:\\n{hr()}')\n",
    "        print(fill(f'{var}'))\n",
    "        var_prop = f'type: {type(var).__name__}'\n",
    "        if isinstance(var, (str, list, set, dict, tuple)):\n",
    "            var_prop = f'{var_prop}, length: {len(var)}'\n",
    "        print(var_prop)\n",
    "    \n",
    "def dict_struct(nested_dict: dict, lvl: int = 0) -> None:\n",
    "    '''Print keys and corresponding value types at each level of nesting\n",
    "    for an arbitrarily nested dictionary. Print structure of nested lists \n",
    "    and tuples within nested_dict. Sequences of elements of more than one\n",
    "    type are described as sequences of object.\n",
    "    '''\n",
    "    spacing = 6 + max([len(key) for key in nested_dict.keys()])\n",
    "    for key, val in nested_dict.items():\n",
    "        val_type = ''\n",
    "        obj_flag = 0\n",
    "        while isinstance(val, (list, tuple)) and not obj_flag:\n",
    "            val_type = (\n",
    "                val_type + bool(val_type) * ': '\n",
    "                + f'{type(val).__name__}'\n",
    "            )\n",
    "            if len(set(type(nested_val) for nested_val in val)) > 1:\n",
    "                val_type = val_type + bool(val_type) * ': ' + 'object '\n",
    "                obj_flag = 1\n",
    "            val = val[0]\n",
    "        if not obj_flag:\n",
    "            val_type = val_type + bool(val_type) * ': ' + type(val).__name__\n",
    "        print(''.join([\n",
    "            2 * lvl * ' ', f'{lvl}[{key}]:'.ljust(spacing), f'{val_type}'\n",
    "        ]))\n",
    "        if isinstance(val, dict):\n",
    "            dict_struct(val, lvl + 1)\n",
    "            \n",
    "def not_none(x: object) -> bool:\n",
    "    return x is not None\n",
    "\n",
    "def dict_agg(\n",
    "        data: dict, col: str, *funcs: callable) -> tuple[float]:\n",
    "    '''Return tuple of aggregate calculations performed on a dictionary\n",
    "    storing numeric data in a tabular structure. If there are null values,\n",
    "    aggregates are calculated on the non-null subset of data[col].\n",
    "    \n",
    "    Arguments:\n",
    "    data -- dictionary of tabular data\n",
    "    col -- string representing column over which aggregates are calculated\n",
    "    *funcs -- list of callable functions that take a sequence as argument\n",
    "    and have a numeric return type (min/max/sum/etc.)\n",
    "    \n",
    "    Return a tuple of floats\n",
    "    '''\n",
    "    return tuple(\n",
    "        func(filter(not_none, data[col]))\n",
    "        for func in funcs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the Nasdaq API to get a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n",
      "_______________________________________________________________________________\n",
      "{'dataset': {'collapse': 'daily',\n",
      "             'column_index': None,\n",
      "             'column_names': ['Date',\n",
      "                              'Open',\n",
      "                              'High',\n",
      "                              'Low',\n",
      "                              'Close',\n",
      "                              'Change',\n",
      "                              'Traded Volume',\n",
      "                              'Turnover',\n",
      "                              'Last Price of the Day',\n",
      "                              'Daily Traded Units',\n",
      "                              'Daily Turnover'],\n",
      "             'data': [['2020-12-01',\n",
      "                       112.2,\n",
      "                       112.2,\n",
      "                       111.5,\n",
      "                       112.0,\n",
      "                       None,\n",
      "                       51.0,\n",
      "                       5703.0,\n",
      "                       None,\n",
      "                       None,\n",
      "                       None]],\n",
      "             'database_code': 'FSE',\n",
      "             'database_id': 6129,\n",
      "             'dataset_code': 'AFX_X',\n",
      "             'description': 'Stock Prices for Carl Zeiss Meditec (2020-11-02) '\n",
      "                            'from the Frankfurt Stock Exchange.<br><br>Trading '\n",
      "                            'System: Xetra<br><br>ISIN: DE0005313704',\n",
      "             'end_date': '2020-12-01',\n",
      "             'frequency': 'daily',\n",
      "             'id': 10095370,\n",
      "             'limit': 1,\n",
      "             'name': 'Carl Zeiss Meditec (AFX_X)',\n",
      "             'newest_available_date': '2020-12-01',\n",
      "             'oldest_available_date': '2000-06-07',\n",
      "             'order': None,\n",
      "             'premium': False,\n",
      "             'refreshed_at': '2020-12-01T14:48:09.907Z',\n",
      "             'start_date': '2000-06-07',\n",
      "             'transform': None,\n",
      "             'type': 'Time Series'}}\n"
     ]
    }
   ],
   "source": [
    "sample = nasdaq_json_dict('FSE', 'AFX_X', collapse = 'daily', limit = '1')\n",
    "print(f'sample\\n{hr()}')\n",
    "pprint.pprint(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the structure of the resultant object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample structure\n",
      "nest level[key]: val type(s)\n",
      "_______________________________________________________________________________\n",
      "0[dataset]:  dict\n",
      "  1[id]:                     int\n",
      "  1[dataset_code]:           str\n",
      "  1[database_code]:          str\n",
      "  1[name]:                   str\n",
      "  1[description]:            str\n",
      "  1[refreshed_at]:           str\n",
      "  1[newest_available_date]:  str\n",
      "  1[oldest_available_date]:  str\n",
      "  1[column_names]:           list: str\n",
      "  1[frequency]:              str\n",
      "  1[type]:                   str\n",
      "  1[premium]:                bool\n",
      "  1[limit]:                  int\n",
      "  1[transform]:              NoneType\n",
      "  1[column_index]:           NoneType\n",
      "  1[start_date]:             str\n",
      "  1[end_date]:               str\n",
      "  1[data]:                   list: list: object \n",
      "  1[collapse]:               str\n",
      "  1[order]:                  NoneType\n",
      "  1[database_id]:            int\n"
     ]
    }
   ],
   "source": [
    "print(f'sample structure\\nnest level[key]: val type(s)\\n{hr()}')\n",
    "dict_struct(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample['dataset']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description:\n",
      "_______________________________________________________________________________\n",
      "Stock Prices for Carl Zeiss Meditec (2020-11-02) from the Frankfurt Stock Exchange.\n",
      "Trading System: Xetra\n",
      "ISIN: DE0005313704\n"
     ]
    }
   ],
   "source": [
    "print(f'description:\\n{hr()}')\n",
    "print(sample['description'].replace('<br><br>', '\\n'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying naming and styling conventions to the column names. Creating a dictionary pairing each column name to a verbose name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_names:\n",
      "_______________________________________________________________________________\n",
      "['date', 'open', 'high', 'low', 'close', 'change', 'traded_volume',\n",
      "'turnover', 'last_price_of_the_day', 'daily_traded_units',\n",
      "'daily_turnover']\n",
      "type: list, length: 11\n"
     ]
    }
   ],
   "source": [
    "column_names = [\n",
    "    col.replace(' ', '_').lower()\n",
    "    for col in sample['column_names']\n",
    "]\n",
    "verbose_names = dict(zip(column_names, [\n",
    "    'date', 'opening price', 'highest price of the day', \n",
    "    'lowest price of the day', 'closing price', 'change', 'traded volume', \n",
    "    'turnover', 'last price of the day', 'daily traded units', \n",
    "    'daily turnover'\n",
    "]))\n",
    "print_vars(column_names = column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the 'data' portion of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data:\n",
      "_______________________________________________________________________________\n",
      "[['2020-12-01', 112.2, 112.2, 111.5, 112.0, None, 51.0, 5703.0, None,\n",
      "None, None]]\n",
      "type: list, length: 1\n"
     ]
    }
   ],
   "source": [
    "sample_data = sample['data']\n",
    "print_vars(sample_data = sample_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting the sample data, a string format constant was added to the imports and constants cell of this notebook. NASDAQ_DATE_FMT specifies the format used in converting the provided date strings to datetime.date objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing sample data as a dictionary following the structure {field: list of values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data_dict:\n",
      "_______________________________________________________________________________\n",
      "{'date': ['2020-12-01'], 'open': [112.2], 'high': [112.2], 'low':\n",
      "[111.5], 'close': [112.0], 'change': [None], 'traded_volume': [51.0],\n",
      "'turnover': [5703.0], 'last_price_of_the_day': [None],\n",
      "'daily_traded_units': [None], 'daily_turnover': [None]}\n",
      "type: dict, length: 11\n"
     ]
    }
   ],
   "source": [
    "sample_data_dict = {\n",
    "    column_names[i]: [row[i] for row in sample_data]\n",
    "    for i in range(len(column_names))\n",
    "}\n",
    "print_vars(sample_data_dict = sample_data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing a row of sample data as a list of namedtuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data_row:\n",
      "_______________________________________________________________________________\n",
      "fse_row(date=datetime.date(2020, 12, 1), open=112.2, high=112.2,\n",
      "low=111.5, close=112.0, change=None, traded_volume=51.0,\n",
      "turnover=5703.0, last_price_of_the_day=None, daily_traded_units=None,\n",
      "daily_turnover=None)\n",
      "type: fse_row, length: 11\n"
     ]
    }
   ],
   "source": [
    "fse_row = namedtuple('fse_row', column_names)\n",
    "sample_data_row = fse_row(\n",
    "    datetime.strptime(sample_data[0][0], NASDAQ_DATE_FMT).date(),\n",
    "    *sample_data[0][1:]\n",
    ")\n",
    "print_vars(sample_data_row = sample_data_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are your tasks for this mini project:\n",
    "\n",
    "1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "2. Convert the returned JSON object into a Python dictionary.\n",
    "3. Calculate what the highest and lowest opening prices were for the stock in this period.\n",
    "4. What was the largest change in any one day (based on High and Low price)?\n",
    "5. What was the largest change between any two days (based on Closing Price)?\n",
    "6. What was the average daily trading volume during this year?\n",
    "7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 1**\n",
    "\n",
    "Getting a json object from the NASDAQ api for Carl Zeiss Meditec on the Frankfurt Stock Exchange in 2017. Decoding this json object into a python dictionary assigned to the variable nasdaq_fse_afx_x_2017. Saving it to the \"raw\" folder in the \"data\" directory of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_fse_afx_x_2017 = nasdaq_json_dict(\n",
    "    'FSE', 'AFX_X', start_date = '2017-01-01', end_date = '2017-12-31'\n",
    ")\n",
    "with open('data/raw/nasdaq_fse_afx_x_2017.json', 'w+') as raw_data:\n",
    "    json.dump(nasdaq_fse_afx_x_2017, raw_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning the relevant portion of raw data to a working variable organized as a list of namedtuples. Converting the provided date strings to datetime.date objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "afx_x_2017 = nasdaq_fse_afx_x_2017['dataset']['data']\n",
    "afx_x_2017 = [\n",
    "    fse_row(\n",
    "        datetime.strptime(row[0], NASDAQ_DATE_FMT).date(),\n",
    "        *row[1:]\n",
    "    ) for row in afx_x_2017\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the percentage of null values for each column in column_names. Removing fields with more than 75% null values from the column_names list and adding them to the removed_columns list. Removing the corresponding key value pairs from the verbose_names dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column                        null values\n",
      "_______________________________________________________________________________\n",
      "date                          0.0%\n",
      "open                          1.2%\n",
      "high                          0.0%\n",
      "low                           0.0%\n",
      "close                         0.0%\n",
      "change                        99.6%\n",
      "turnover                      0.0%\n",
      "last_price_of_the_day         100.0%\n",
      "daily_turnover                100.0%\n",
      "_______________________________________________________________________________\n",
      "\n",
      "removed columns:  ['change', 'last_price_of_the_day', 'daily_turnover']\n",
      "retained columns: ['date', 'open', 'high', 'low', 'close', 'traded_volume', 'turnover', 'daily_traded_units']\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"column\".ljust(30)}null values\\n{hr()}')\n",
    "removed_columns = []\n",
    "for col in column_names:\n",
    "    null_pct = fmean([int(getattr(row, col) is None) for row in afx_x_2017])\n",
    "    print(f'{col.ljust(30)}{round(null_pct * 100, 1)}%')\n",
    "    mostly_null = null_pct > 0.75\n",
    "    if mostly_null:\n",
    "        removed_columns.append(col)\n",
    "        column_names.remove(col)\n",
    "        verbose_names.pop(col)\n",
    "print(f'{hr()}\\n\\nremoved columns:  {removed_columns}')      \n",
    "print(f'retained columns: {column_names}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list of dates missing an opening price to fill from another source, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates missing opening prices:\n",
      "_______________________________________________________________________________\n",
      "2017-05-01\n",
      "2017-04-17\n",
      "2017-04-14\n"
     ]
    }
   ],
   "source": [
    "missing_open_price = [row for row in afx_x_2017 if row.open is None]\n",
    "print(f'dates missing opening prices:\\n{hr()}')\n",
    "for row in missing_open_price:\n",
    "    print(row.date.isoformat())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "\n",
    "Reorganizing data as a nested dictionary keyed by date. The structure is {date: {field: value}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "afx_x_2017_d = {\n",
    "    row.date: {field: getattr(row, field) for field in column_names} \n",
    "    for row in afx_x_2017\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{datetime.date(2017, 12, 27): {'close': 51.82,\n",
      "                               'daily_traded_units': None,\n",
      "                               'date': datetime.date(2017, 12, 27),\n",
      "                               'high': 51.89,\n",
      "                               'low': 50.76,\n",
      "                               'open': 51.45,\n",
      "                               'traded_volume': 57452.0,\n",
      "                               'turnover': 2957018.0},\n",
      " datetime.date(2017, 12, 28): {'close': 51.6,\n",
      "                               'daily_traded_units': None,\n",
      "                               'date': datetime.date(2017, 12, 28),\n",
      "                               'high': 51.82,\n",
      "                               'low': 51.43,\n",
      "                               'open': 51.65,\n",
      "                               'traded_volume': 40660.0,\n",
      "                               'turnover': 2099024.0},\n",
      " datetime.date(2017, 12, 29): {'close': 51.76,\n",
      "                               'daily_traded_units': None,\n",
      "                               'date': datetime.date(2017, 12, 29),\n",
      "                               'high': 51.94,\n",
      "                               'low': 51.45,\n",
      "                               'open': 51.76,\n",
      "                               'traded_volume': 34640.0,\n",
      "                               'turnover': 1792304.0}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint({\n",
    "    key: afx_x_2017_d[key] \n",
    "    for key in list(afx_x_2017_d.keys())[:3]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "\n",
    "Unsure of the requirements for task 2, reorganizing data as an alternate dictionary of lists keyed by field, following the structure {field: list of values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afx_x_2017_f\n",
      "_______________________________________________________________________________\n",
      "{'close': [51.76, 51.6, 51.82],\n",
      " 'daily_traded_units': [None, None, None],\n",
      " 'date': [datetime.date(2017, 12, 29),\n",
      "          datetime.date(2017, 12, 28),\n",
      "          datetime.date(2017, 12, 27)],\n",
      " 'high': [51.94, 51.82, 51.89],\n",
      " 'low': [51.45, 51.43, 50.76],\n",
      " 'open': [51.76, 51.65, 51.45],\n",
      " 'traded_volume': [34640.0, 40660.0, 57452.0],\n",
      " 'turnover': [1792304.0, 2099024.0, 2957018.0]}\n"
     ]
    }
   ],
   "source": [
    "afx_x_2017_f = {\n",
    "    col: [getattr(row, col) for row in afx_x_2017]\n",
    "    for col in column_names\n",
    "}\n",
    "print(f'afx_x_2017_f\\n{hr()}')\n",
    "pprint.pprint({key: afx_x_2017_f[key][:3] for key in afx_x_2017_f.keys()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a nested dictionary of summary statistics by column. The structure is {field : {statistic name : statistic value}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening price\n",
      "min:      € 34.00\n",
      "max:      € 53.11\n",
      "mean:     € 43.34\n",
      "median:   € 43.45\n",
      "\n",
      "closing price\n",
      "min:      € 34.06\n",
      "max:      € 53.09\n",
      "mean:     € 43.36\n",
      "median:   € 43.28\n",
      "\n",
      "highest price of the day\n",
      "min:      € 34.12\n",
      "max:      € 53.54\n",
      "mean:     € 43.70\n",
      "median:   € 43.55\n",
      "\n",
      "lowest price of the day\n",
      "min:      € 33.62\n",
      "max:      € 52.48\n",
      "mean:     € 42.92\n",
      "median:   € 42.62\n",
      "\n",
      "traded volume\n",
      "min:      45.00\n",
      "max:      670349.00\n",
      "mean:     89124.34\n",
      "median:   76286.00\n",
      "\n",
      "turnover\n",
      "min:      1980.00\n",
      "max:      25910543.00\n",
      "mean:     3853589.45\n",
      "median:   3292223.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "afx_x_2017_summary = {\n",
    "    field: dict(zip(\n",
    "        ('min', 'max', 'mean', 'median'),\n",
    "        dict_agg(afx_x_2017_f, field, *[min, max, fmean, median])\n",
    "    )) for field in [\n",
    "        'open', 'close', 'high', 'low', 'traded_volume', 'turnover'\n",
    "    ]\n",
    "}\n",
    "\n",
    "for col, aggs in afx_x_2017_summary.items():\n",
    "    print(f'{verbose_names[col]}')\n",
    "    euro = ('price' in verbose_names[col]) * '€ '\n",
    "    for name, val in aggs.items():\n",
    "        print(f'{name}: '.ljust(10) + f'{euro}{round(val, 2):.2f}')\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking work from previous steps. Assigning answers for remaining tasks to variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerating dates in dataset for use as indices in window functions\n",
    "trading_dates = sorted(afx_x_2017_d.keys())\n",
    "trading_dates = dict(enumerate(trading_dates))\n",
    "\n",
    "# minimum and maximum opening prices\n",
    "min_open, max_open = dict_agg(afx_x_2017_f, 'open', *[min, max])\n",
    "\n",
    "# largest price change over one day\n",
    "price_deltas = [afx_x_2017_d[day]['high'] - afx_x_2017_d[day]['low'] for day in afx_x_2017_d]\n",
    "max_price_delta = round(max(price_deltas), 2)\n",
    "    \n",
    "# maximum difference in closing value between any two dates\n",
    "min_close, max_close = dict_agg(afx_x_2017_f, 'close', *[min, max])\n",
    "max_close_difference = round(max_close - min_close, 2)\n",
    "\n",
    "# maximum difference between closing prices of two consecutive calendar dates\n",
    "max_close_diff_consec_calendar = round(max(\n",
    "    [\n",
    "        abs(afx_x_2017_d[day]['close'] \n",
    "        - afx_x_2017_d[day + timedelta(days = 1)]['close'])\n",
    "        for day in\n",
    "            [\n",
    "                dy for dy in sorted(afx_x_2017_d.keys())[:-1]\n",
    "                if dy + timedelta(days = 1) in afx_x_2017_d\n",
    "            ]\n",
    "    ]\n",
    "), 2)\n",
    "\n",
    "# maximium difference between closing prices of consecutive open trading dates\n",
    "max_close_diff_consec_open = round(max([\n",
    "    abs(\n",
    "        afx_x_2017_d[trading_dates[i]]['close'] \n",
    "        - afx_x_2017_d[trading_dates[i + 1]]['close']\n",
    "    )\n",
    "    for i in range(len(trading_dates) - 1)\n",
    "]), 2)\n",
    "\n",
    "\n",
    "# average traded volume\n",
    "avg_daily_traded_volume, median_traded_volume = dict_agg(\n",
    "    afx_x_2017_f, 'traded_volume', *[fmean, median]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3, 4, 5, 6, 7**\n",
    "\n",
    "Printing a list of reponses for tasks 3 through 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks 3-7\n",
      "_______________________________________________________________________________\n",
      "3. The lowest opening price in 2017 was €34.00\n",
      "3. The highest opening price was €53.11\n",
      "4. The largest change in price over the course of one day was €2.81\n",
      "5. The largest difference in closing price of two dates was €19.03\n",
      "5. The largest difference in closing price between two consecutive\n",
      "   calendar dates was €2.56\n",
      "5. The largest difference in closing price between two consecutive\n",
      "   trading dates was €2.56\n",
      "6. The average daily traded volume was 89124.34\n",
      "7. The median daily traded volume was 76286.00\n"
     ]
    }
   ],
   "source": [
    "print(f'tasks 3-7\\n{hr()}')\n",
    "statements = [\n",
    "    f'3. The lowest opening price in 2017 was €{afx_x_2017_summary[\"open\"][\"min\"]:.2f}',\n",
    "    f'3. The highest opening price was €{afx_x_2017_summary[\"open\"][\"max\"]:.2f}',\n",
    "    f'4. The largest change in price over the course of one day was €{max_price_delta:.2f}',\n",
    "    f'5. The largest difference in closing price of two dates was €{max_close_difference:.2f}',\n",
    "    f'5. The largest difference in closing price between two consecutive calendar dates was '\n",
    "    + f'€{max_close_diff_consec_calendar:.2f}',\n",
    "    f'5. The largest difference in closing price between two consecutive trading dates was '\n",
    "    + f'€{max_close_diff_consec_open:.2f}',\n",
    "    f'6. The average daily traded volume was {round(avg_daily_traded_volume, 2):.2f}',\n",
    "    f'7. The median daily traded volume was {median_traded_volume:.2f}'\n",
    "]\n",
    "for statement in statements:\n",
    "    print(fill(statement, subsequent_indent = '   '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7635eb1b9d0fe97add78a7368b6b431c09bb8ad5c42e437d64abdd99821c31ae"
  },
  "kernelspec": {
   "display_name": "Python 3 SBDSCT Unit 7.2.5",
   "language": "python",
   "name": "springboard_dsct_u7_2_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
